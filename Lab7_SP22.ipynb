{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summations**.  We did summations earlier, but say we have a list of $x$ values, and we want to perform the summation:\n",
    "$$S = \\sum_i x_i \\cos(\\pi x_i)$$\n",
    "We can do this summation with a ``for loop``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_values = np.array([0, 1, 2, 3, 4, 5])\n",
    "Summation_value = 0\n",
    "for i in range(len(x_values)):\n",
    "    Summation_value = Summation_value + x_values[i] * np.cos(np.pi * x_values[i])\n",
    "print(Summation_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above,\n",
    "- The first line sets up a list of numbers, ``x_values`` that will be summed over\n",
    "- The initialization line, ``Summation_value = 0``, just sets up the summation\n",
    "- The ``for`` loop combined with ``Summation_value = Summation_value + ...`` will cycle through the different ``x_values`` and successively add the terms in the series.\n",
    "- Finally the print statement is needed to report the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it with a brief example.  If:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x_values = np.array([1, 3, 5, 7, 9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write code that calculates $S = \\sum_i x_i$, using the ``new_x_values`` array to perform the summation.  Your code should perform the summation using:\n",
    "- the initialization of a variable, \n",
    "- using a ``for`` loop to do the summation, and\n",
    "- print the result and confirm that it is 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\chi^2$-fitting\n",
    "\n",
    "``fitteia`` and other ways of using data to infer physical information will typically use $\\chi^2$ fitting when you have data with error bars.  The crux of the method is as follows:  when creating a best-fit curve, data points with small error bars are well known, so the best-fit curve should be closest to those, and data points with larger error bars are less-well-known, so the best-fit curve can be further away from these.\n",
    "\n",
    "To do so, we create a statistic called $\\chi^2$:\n",
    "$$\\chi^2 = \\sum_i \\frac{(y_i - f (x_i))^2}{\\sigma_i^2}$$\n",
    "In this formula, we assume our data gives us three lists of numbers:\n",
    "- The $x_i$ are the ``independent_variables[i]``.\n",
    "- The $y_i$ are the ``data[i]``.\n",
    "- The $\\sigma_i$ are the ``uncertainties[i]``.\n",
    "\n",
    "$f (x_i)$ is a model that we're trying to find the best fit values for.\n",
    "\n",
    "The summation means to calculate the fraction for each individual ``i``, and add up the contribution.  We note that if the data are very close to the model, $\\chi^2$ is small, otherwise it can be big.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First,** let's load some data and make a graph.  Download ``Lab7Data.csv`` from Blackboard, and put it in the same folder as this lab (just like when you uploaded the lab into the home page of jupyter notebook).  Then:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "independent_variables, data, uncertainties = np.loadtxt('Lab7Data.csv',delimiter=',',usecols=(0,1,2),unpack=True)\n",
    "plt.figure()\n",
    "plt.errorbar(independent_variables, data, yerr = uncertainties, fmt='o')\n",
    "plt.xlim(-0.1,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code,\n",
    "- ``np.loadtxt()`` takes the data into the three arrays described above.\n",
    "- ``plt.errorbar( )`` creates the error bar plot:\n",
    "    - The first term is the x-axis\n",
    "    - The second term is the y-axis\n",
    "    - The ``yerr = uncertainties`` uses the array of uncertainties corresponding to the x and y values.\n",
    "    - ``fmt = 'o'`` creates a dot at the data point, with the error bars above and below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like a line can be drawn through these data points and their error bars, so let's choose our model to be $f (x) = m x$.  The slope, $m$, is something that we want to find the slope that best fits the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we want to find the best value of $m$, we should create a function.\n",
    "In this function, you should use the arrays: ``independent_variables``, ``data``, and ``uncertainties`` as $x_i$, $y_i$, $\\sigma_i$, respectively, to calculate:\n",
    "$$\\chi^2 (m) = \\sum_i \\frac{(y_i - m x_i)^2}{\\sigma_i^2}$$\n",
    "Write a function, ``chi_squared()`` to calculate $\\chi^2 (m)$, with inputs:\n",
    "- ``m``, the slope in our model\n",
    "- ``x``, the independent variables array\n",
    "- ``y`` the data array\n",
    "- ``sigma`` the uncertainties array\n",
    "\n",
    "Your function should then calculate the value of $\\chi^2$ with the input value of $m$, then ``return`` the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your result by noting that when $m = 5$, that $\\chi^2 = 7.12$, so when we call ``chi_squared(5, independent_variables, data, uncertainties)``, your code should return 7.12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the \"best fit slope,\" the best value of $m$, we need to find the value of $m$ that minimizes $\\chi^2 (m)$.  One way to do this is to first create an array of $\\chi^2$ values that correspond to $m$ values.  Do the following:\n",
    "- Create an array of $m$ values, ``m_values``, linearly spaced between 3 and 8 with 100 points.\n",
    "- Create an array of zeros to store all the $\\chi^2$ values, ``chi_values``\n",
    "- Use a ``for`` loop along with the ``chi_squared`` function to create all these values and place it in the array.  You want each ``chi_values[i]`` to correspond to the $\\chi^2$ value using ``m_values[i]``.\n",
    "\n",
    "All these steps are the steps you would take to make a plot of $\\chi^2$ vs. $m$ for $m$ between 3 and 8.  So, first make a plot of $\\chi^2$ vs. $m$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can find the minimum.  If we called our array of $m$ ``m_values`` and our array of $\\chi^2$ ``chi_values``, then:\n",
    "- ``np.min(chi_values)`` will give you the minimum $\\chi^2$ value, but it won't tell you what $m$ value makes it.\n",
    "- ``np.argmin(chi_values)`` will tell you the index value that has the minimum.  It tells you which number has the minimum $\\chi^2$.\n",
    "- ``m_values[np.argmin(chi_values)]`` will then tell you the value of $m$ that minimizes $\\chi^2$.  This is the best-fit slope.\n",
    "\n",
    "Determine the minimum $\\chi^2$ value and the value of $m$ that makes it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should've found that the minimum $\\chi^2$ is 6.55 and this corresponds to $m = 5.27$.  This is the best fit slope.  However, as scientists we also want uncertainty on this slope.  The statistics related to $\\chi^2$ tell us that the error bars should extend between the $m$ values that have $\\chi^2 = 7.55$ (this is one plus the minimum $\\chi^2$ value).  So, we need to find which $m$ values correspond to this new value.  We can do this with ``np.where()``.  \n",
    "- First, use ``np.where(chi_values < 7.55)``.  This will tell you all the indices that have $\\chi^2 < 7.55$.\n",
    "- Take the smallest index, ``print(m_values[ ])``, where you put that smallest value in the ``[ ]``.\n",
    "- Repeat with the largest index.\n",
    "\n",
    "These two numbers represent the bottom and top of the error bar.  To find the uncertainty, find the difference of the two, and divide by two.  Report your uncertainty in the commented box below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The best-fit slope is m = ___ +/- ___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make this procedure more fit for computation.  Start with the following (**if you did not name your array ``chi_values`` you're going to need to rename it**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = np.where(chi_values < np.min(chi_values)+1)[0]\n",
    "print(indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can find the first and last index from the list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(indexes[0], indexes[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice, we can count terms in an array as 0, 1, ...; we can also count backward -1, -2, ...; Use ``indexes[0]`` and ``indexes[-1]`` to write an expression to find the uncertainty using ``m_values``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we want to create a plot with both the data and the best fit line.  We know how to make the errorbar plot, we did that near the beginning of this lab.  To add a line to the plot we should do the following:\n",
    "- First create a function, ``f(x)``, that returns ``5.27 * x``, which is the best fit line.\n",
    "- Next create a plot for x-values from -0.1 to 1, and using a loop to do the corresponding y-values, as always.\n",
    "- immediately above your ``plt.errorbar`` command, include a ``plt.plot`` command, which will first create the best-fit line, then add the error-bar plot over it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Completing this lab in its entirety is Homework 7.  Please Submit by Monday, April 4\n",
    "\n",
    "Before you submit, make sure that your code works with Kernel > Restart & Run All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
